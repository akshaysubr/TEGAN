# Turbulence Enrichment using Generative Adversarial Networks


## What and why
Turbulent flow is important in many engineering applications. However, simulating turbulence is very computationally expensive due to extremely high resolution requirements. Large Eddy Simulations (LES) that simulate only the large scales have become popular due much lower cost, but require explicit modeling of the small scales. Here, we propose to enrich LES data by populating it with small scales obtained using a Generative Adversarial Network (GAN).

Modeling turbulence accurately is extremely challenging especially in capturing high order statistics due to its intermittent nature. GANs have been shown to perform better than other data driven approaches like PCA in capturing high order moments [[1]](https://arxiv.org/pdf/1708.01810.pdf). In addition, generating physically realistic realizations are important for physical simulation data; a constraint not present when using generative models for images. Incorporating this constraint into the GAN framework would be crucial to its performance. The constraint is given by the governing equations for the incompressible flow given below:

<p align="center"><img alt="\begin{align*}&#10;\nabla \cdot \bm{u} &amp;= 0 \\&#10;\frac{\partial \bm{u}}{\partial t} + \left( \bm{u} \cdot \nabla \right) \bm{u} &amp;= - \nabla p + \frac{1}{\mathrm{Re}} \nabla^2 \bm{u}&#10;\end{align*}" src="figures/68ff53efbcb20ecf0dc2e6c6737fc1db.png?invert_in_darkmode" align="middle" width="238.44975pt" height="57.49623pt"/></p>


## Data
We generated data for this work using an in-house fluid flow simulation code (PadeOps) which was run on a compute cluster using 256 processors for multiple days. We performed a time-evolving simulation on a 64x64x64 uniform grid and collected snapshots separated in time by more than one integral time scale. The output is comprised of four fields --- three components of the velocity vector <img alt="$(u, v, w)$" src="figures/137697103c767fa253152852dcdcd1e3.png?invert_in_darkmode" align="middle" width="57.38535pt" height="24.56553pt"/> and one of the pressure <img alt="$(p)$" src="figures/a6d39abaea580bf97a615476a03468a0.png?invert_in_darkmode" align="middle" width="20.97744pt" height="24.56553pt"/> each of size <img alt="$64 \times 64 \times 64$" src="figures/96a4d8ddfb5661c03d2199e3d3014e99.png?invert_in_darkmode" align="middle" width="89.217975pt" height="21.10812pt"/>.

Low-resolution data is generated by filtering the HR data down to <img alt="$16 \times 16 \times 16$" src="figures/b76741a17852bb26ff8e4b2f7300561d.png?invert_in_darkmode" align="middle" width="89.217975pt" height="21.10812pt"/> using the explicit filter shown below that's derived as a best approximation to the sharp spectral filter.
<div style="text-align:center"><img src="figures/transfer_function.png" title="Transfer function of the compact support filter used compared to the 1/4 sharp spectral filter" style="width: 400px;"></div>

Comparison of the high-resolution (top) and low resolution (bottom) data:
<div style="text-align:center"><img src="figures/HR_LR_comparison.png" title="Comparison of low and high resolution data on a slice" style="width: 600px;"></div>

Comparison of the power spectral density of the high-resolution (blue) and low-resolution (orange) data:
<div style="text-align:center"><img src="figures/HIT_064_spectra.svg" title="Comparison of the spectra of low and high resolution data" style="width: 400px;"></div>


The <img alt="$1260$" src="figures/c12a5dd0a140dc46190a0de47b605d28.png?invert_in_darkmode" align="middle" width="32.753985pt" height="21.10812pt"/> datasets are split into <img alt="$920\ (79.3\%)$" src="figures/e02a1244bad4c5707d05471f3caa41be.png?invert_in_darkmode" align="middle" width="85.54491pt" height="24.56553pt"/> train, <img alt="$120\ (10.3\%)$" src="figures/aab851f1f506f50c6455a7b3e7fdf60e.png?invert_in_darkmode" align="middle" width="85.54491pt" height="24.56553pt"/> dev and <img alt="$120\ (10.3\%)$" src="figures/aab851f1f506f50c6455a7b3e7fdf60e.png?invert_in_darkmode" align="middle" width="85.54491pt" height="24.56553pt"/> test sets.

## Model
For the task of upsampling the low resolution data in a physically consistent manner, we use a GAN[[2]](https://arxiv.org/pdf/1406.2661.pdf) in a fashion similar to super-resolution applications for image data [[3]](https://arxiv.org/pdf/1609.04802.pdf). 

The generator has a deep residual network architecture with each residual block having convolutional layers with batch normalization. The discriminator has a deep convolutional architecture with fully connected layers in the end for binary classification. The architectures of the generator and discriminator are depicted pictorially below:
<div style="text-align:center"><img src="figures/TEGAN.png" title="Architecture for the generator and discriminator in TEGAN" style="width: 1200px;"></div>

### Loss Functions
The flow field is constrained by the continuity and pressure Poisson equations:
<p align="center"><img alt="\begin{gather}&#10;\nabla \cdot \bm{u} = 0, \tag{\text{continuity}} \label{eqn:continuity} \\&#10;- \nabla^2 p = \nabla \bm{u} : \nabla \bm{u}^T \tag{\text{pressure Poisson}} \label{eqn:pressure_poisson}&#10;\end{gather}" src="figures/072613ac100a8bbf2eb79caf4db2d813.png?invert_in_darkmode" align="middle" width="419.03235pt" height="43.5204pt"/></p>

The above equations might not be satisfied exactly by the model's generated output. To combat this, the residual of the above equations can be used as a regularizer for the model through a physics loss.

The loss function minimized for the generator network during training is a combination of
<p align="center"><img alt="\begin{align*}&#10;\mathcal{L}_\mathrm{GAN} &amp;= \left( 1 - \lambda_\mathrm{A} \right) \mathcal{L}_\mathrm{resnet} + \lambda_\mathrm{A} \mathcal{L}_\mathrm{adversarial}\\&#10;\mathcal{L}_\mathrm{resnet} &amp;= \left( 1 - \lambda_\mathrm{P} \right) \mathcal{L}_\mathrm{content} + \lambda_\mathrm{P} \mathcal{L}_\mathrm{physics} \\&#10;\mathcal{L}_\mathrm{content} &amp;= \left( 1 - \lambda_\mathrm{E} \right) \mathcal{L}_\mathrm{MSE} + \lambda_\mathrm{E} \mathcal{L}_\mathrm{enstrophy} \\&#10;\mathcal{L}_\mathrm{physics} &amp;= \left( 1 - \lambda_\mathrm{C} \right) \mathcal{L}_\mathrm{pressure} + \lambda_\mathrm{C} \mathcal{L}_\mathrm{continuity}&#10;\end{align*}" src="figures/c096094e1e978a4b3fba43a8736c342d.png?invert_in_darkmode" align="middle" width="307.8009pt" height="90.950145pt"/></p>


* **Content loss**: <img alt="$\mathcal{L}_\mathrm{content}$" src="figures/2386a50acaa17111a67fb9f710bf83d3.png?invert_in_darkmode" align="middle" width="53.463795pt" height="22.38192pt"/>

<img alt="$\mathcal{L}_\mathrm{MSE}$" src="figures/e62a05a67637ed806d3ae7c8119e4a92.png?invert_in_darkmode" align="middle" width="39.11391pt" height="22.38192pt"/>: Mean squared error between the high resolution and generated fields

<img alt="$\mathcal{L}_\mathrm{enstrophy}$" src="figures/8bffdecc48a4b5f9e448880ac778a454.png?invert_in_darkmode" align="middle" width="67.473285pt" height="22.38192pt"/>: Mean squared error in the derived enstrophy field <img alt="$\Omega$" src="figures/9432d83304c1eb0dcb05f092d30a767f.png?invert_in_darkmode" align="middle" width="11.82786pt" height="22.38192pt"/> (<img alt="$\Omega = \bm{\omega} \cdot \bm{\omega},\ \mathrm{where}\ \bm{\omega}=\nabla \times \bm{u}$" src="figures/11f95d18369d80a243daf4f6615ed2d6.png?invert_in_darkmode" align="middle" width="209.662695pt" height="22.74591pt"/>) to sensitize the generator to high frequency content

* **Physics loss**: <img alt="$\mathcal{L}_\mathrm{physics}$" src="figures/04d70c73cd6ac876b12f68ab24eba7c9.png?invert_in_darkmode" align="middle" width="52.195935pt" height="22.38192pt"/>

Residuals of the continuity (<img alt="$\mathcal{L}_\mathrm{continuity}$" src="figures/2a0b6f3ee5b1f8bea2956597e05ac52d.png?invert_in_darkmode" align="middle" width="68.992275pt" height="22.38192pt"/>) and pressure Poisson (<img alt="$\mathcal{L}_\mathrm{pressure}$" src="figures/dbae18b59f1f4898692f15de5c1f2cd8.png?invert_in_darkmode" align="middle" width="58.02027pt" height="22.38192pt"/>) equations given above similar to [[4]](https://arxiv.org/pdf/1711.10561.pdf).

<div style="text-align:center"><img src="figures/physics_loss_schematic.png" title="Schematic representing the role of the physics loss as a regularizer and as an enforcer of the physical realizability constraint" style="width: 300px;"></div>

* **Adversarial loss**: <img alt="$\mathcal{L}_\mathrm{adversarial}$" src="figures/c6a11bcd1946e4a8b8bc201017a2fc83.png?invert_in_darkmode" align="middle" width="73.30191pt" height="22.38192pt"/>


To train the discriminator, we use the logistic loss based on predicted labels for real and generated data.

### Training

#### TEResNet
A model with just the residual generator network without the adversarial component is termed TEResNet. We first train TEResNet to convergence and tune hyperparameters like the number of residual blocks and the physics loss parameters.

#### TEGAN
The model with both the residual network generator and the discriminator depicted above is termed TEGAN. The generator in TEGAN is first initialized using the weights from the trained TEResNet while the discriminator is initialized using the Xavier-He initialization. 

For the first few iterations in the training process (~300), the discriminator alone is trained to negate the advantage that the generator has because of its pre-trained weights. Then, both the generator and discriminator are trained together with the active adversarial loss until the losses saturate and the discriminator's output saturates at 0.5.

## Model Performance
<div style="text-align:center"><img src="figures/model_performance_u.png" title="Comparison of a u velocity slice between bicubic interpolation, TEResNet and TEGAN" style="width: 800px;"></div>
<div style="text-align:center"><img src="figures/model_performance_v.png" title="Comparison of a v velocity slice between bicubic interpolation, TEResNet and TEGAN" style="width: 800px;"></div>
<div style="text-align:center"><img src="figures/model_performance_w.png" title="Comparison of a w velocity slice between bicubic interpolation, TEResNet and TEGAN" style="width: 800px;"></div>
<div style="text-align:center"><img src="figures/model_performance_p.png" title="Comparison of a pressure slice between bicubic interpolation, TEResNet and TEGAN" style="width: 800px;"></div>


<table align="center">
  <tr>
    <td></td>
    <td colspan="2"><b>Content loss</b></td>
    <td colspan="2"><b>Physics loss</b></td>
  </tr>
  <tr>
    <td></td>
    <td><b>Dev</b></td>
    <td><b>Test</b></td>
    <td><b>Dev</b></td>
    <td><b>Test</b></td>
  </tr>
  <tr>
    <td><b>TEResNet</b></td>
    <td>0.049</td>
    <td>0.050</td>
    <td>0.078</td>
    <td>0.085</td>
  </tr>
  <tr>
    <td><b>TEGAN</b></td>
    <td>0.047</td>
    <td>0.047</td>
    <td>0.070</td>
    <td>0.072</td>
  </tr>
  <tr>
    <td><b>% difference</b></td>
    <td>4.1</td>
    <td>6.0</td>
    <td>10.3</td>
    <td>15.2</td>
  </tr>
</table>

<div style="text-align:center"><img src="figures/model_performance_spectra.png" title="Comparison of the velocity energy spectra between bicubic interpolation, TEResNet and TEGAN" style="width: 500px;"></div>

## References
[1] Chan, Shing, and Ahmed H. Elsheikh. "Parametrization and Generation of Geological Models with Generative Adversarial Networks." arXiv preprint arXiv:1708.01810 (2017).

[2] Goodfellow, Ian, et al. "Generative adversarial nets." Advances in neural information processing systems. 2014.

[3] Ledig, Christian, et al. "Photo-realistic single image super-resolution using a generative adversarial network." arXiv preprint (2016).

[4] Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. "Physics Informed Deep Learning (Part I): Data-driven Solutions of Nonlinear Partial Differential Equations." arXiv preprint arXiv:1711.10561 (2017).

[5] Arjovsky, Martin, Soumith Chintala, and Léon Bottou. "Wasserstein GAN." arXiv preprint arXiv:1701.07875 (2017)
[6] Langr, Jakub and Vladimir Bok. "GANs in Action." https://www.manning.com/books/gans-in-action (2018)
## People
Raunak Borker, Sravya Nimmagadda, Akshay Subramaniam and Man-Long Wong
